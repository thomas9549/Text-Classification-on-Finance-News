{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b641c8",
   "metadata": {},
   "source": [
    "### In the following project, I will train a Bidirectional Encoder Representations from Transformers(BERT) using datas collected out of English news on all listed companies in OMX Helsinki. The dataset consists of 4840 sentences from English language financial news categorised by sentiment. The dataset is divided by agreement rate of 5-8 annotators and I will choose the 3453 entries where at least 75% of the annotators agree with the lable.\n",
    "\n",
    "### And in the second part of the project, similarly, I will build my custom model for text classification based on FinBERT, a pre-trained BERT model that was more specifically for analyzing finance news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ff168c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: transformers[sentencepiece]\r\n"
     ]
    }
   ],
   "source": [
    "# Install two libraries created by the Huggingface team\n",
    "!pip install transformers[sentencepiece] datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfc796b",
   "metadata": {},
   "source": [
    "### Datasets Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d35069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z3/nr4tym2s3v17r9yd_1z14x_80000gn/T/ipykernel_11623/809330691.py:2: FutureWarning: list_datasets is deprecated and will be removed in the next major version of datasets. Use 'huggingface_hub.list_datasets' instead.\n",
      "  list_datasets()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['acronym_identification',\n",
       " 'ade_corpus_v2',\n",
       " 'adversarial_qa',\n",
       " 'aeslc',\n",
       " 'afrikaans_ner_corpus',\n",
       " 'ag_news',\n",
       " 'ai2_arc',\n",
       " 'air_dialogue',\n",
       " 'ajgt_twitter_ar',\n",
       " 'allegro_reviews',\n",
       " 'allocine',\n",
       " 'alt',\n",
       " 'amazon_polarity',\n",
       " 'amazon_reviews_multi',\n",
       " 'amazon_us_reviews',\n",
       " 'ambig_qa',\n",
       " 'americas_nli',\n",
       " 'ami',\n",
       " 'amttl',\n",
       " 'anli',\n",
       " 'app_reviews',\n",
       " 'aqua_rat',\n",
       " 'aquamuse',\n",
       " 'ar_cov19',\n",
       " 'ar_res_reviews',\n",
       " 'ar_sarcasm',\n",
       " 'arabic_billion_words',\n",
       " 'arabic_pos_dialect',\n",
       " 'arabic_speech_corpus',\n",
       " 'arcd',\n",
       " 'arsentd_lev',\n",
       " 'art',\n",
       " 'arxiv_dataset',\n",
       " 'ascent_kb',\n",
       " 'aslg_pc12',\n",
       " 'asnq',\n",
       " 'asset',\n",
       " 'assin',\n",
       " 'assin2',\n",
       " 'atomic',\n",
       " 'autshumato',\n",
       " 'facebook/babi_qa',\n",
       " 'banking77',\n",
       " 'bbaw_egyptian',\n",
       " 'bbc_hindi_nli',\n",
       " 'bc2gm_corpus',\n",
       " 'beans',\n",
       " 'best2009',\n",
       " 'bianet',\n",
       " 'bible_para',\n",
       " 'big_patent',\n",
       " 'billsum',\n",
       " 'bing_coronavirus_query_set',\n",
       " 'biomrc',\n",
       " 'biosses',\n",
       " 'blbooks',\n",
       " 'blbooksgenre',\n",
       " 'blended_skill_talk',\n",
       " 'blimp',\n",
       " 'blog_authorship_corpus',\n",
       " 'bn_hate_speech',\n",
       " 'bnl_newspapers',\n",
       " 'bookcorpus',\n",
       " 'bookcorpusopen',\n",
       " 'boolq',\n",
       " 'bprec',\n",
       " 'break_data',\n",
       " 'brwac',\n",
       " 'bsd_ja_en',\n",
       " 'bswac',\n",
       " 'c3',\n",
       " 'c4',\n",
       " 'cail2018',\n",
       " 'caner',\n",
       " 'capes',\n",
       " 'casino',\n",
       " 'catalonia_independence',\n",
       " 'cats_vs_dogs',\n",
       " 'cawac',\n",
       " 'cbt',\n",
       " 'cc100',\n",
       " 'cc_news',\n",
       " 'ccaligned_multilingual',\n",
       " 'cdsc',\n",
       " 'cdt',\n",
       " 'cedr',\n",
       " 'cfq',\n",
       " 'chr_en',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'circa',\n",
       " 'civil_comments',\n",
       " 'clickbait_news_bg',\n",
       " 'climate_fever',\n",
       " 'clinc_oos',\n",
       " 'clue',\n",
       " 'cmrc2018',\n",
       " 'cmu_hinglish_dog',\n",
       " 'cnn_dailymail',\n",
       " 'coached_conv_pref',\n",
       " 'coarse_discourse',\n",
       " 'codah',\n",
       " 'code_search_net',\n",
       " 'code_x_glue_cc_clone_detection_big_clone_bench',\n",
       " 'code_x_glue_cc_clone_detection_poj104',\n",
       " 'code_x_glue_cc_cloze_testing_all',\n",
       " 'code_x_glue_cc_cloze_testing_maxmin',\n",
       " 'code_x_glue_cc_code_completion_line',\n",
       " 'code_x_glue_cc_code_completion_token',\n",
       " 'code_x_glue_cc_code_refinement',\n",
       " 'code_x_glue_cc_code_to_code_trans',\n",
       " 'code_x_glue_cc_defect_detection',\n",
       " 'code_x_glue_ct_code_to_text',\n",
       " 'code_x_glue_tc_nl_code_search_adv',\n",
       " 'code_x_glue_tc_text_to_code',\n",
       " 'code_x_glue_tt_text_to_text',\n",
       " 'com_qa',\n",
       " 'common_gen',\n",
       " 'common_language',\n",
       " 'common_voice',\n",
       " 'commonsense_qa',\n",
       " 'competition_math',\n",
       " 'compguesswhat',\n",
       " 'conceptnet5',\n",
       " 'conll2000',\n",
       " 'conll2002',\n",
       " 'conll2003',\n",
       " 'conllpp',\n",
       " 'consumer-finance-complaints',\n",
       " 'conv_ai',\n",
       " 'conv_ai_2',\n",
       " 'conv_ai_3',\n",
       " 'conv_questions',\n",
       " 'coqa',\n",
       " 'allenai/cord19',\n",
       " 'cornell_movie_dialog',\n",
       " 'cos_e',\n",
       " 'cosmos_qa',\n",
       " 'counter',\n",
       " 'covid_qa_castorini',\n",
       " 'covid_qa_deepset',\n",
       " 'covid_qa_ucsd',\n",
       " 'covid_tweets_japanese',\n",
       " 'covost2',\n",
       " 'cppe-5',\n",
       " 'craigslist_bargains',\n",
       " 'crawl_domain',\n",
       " 'crd3',\n",
       " 'crime_and_punish',\n",
       " 'crows_pairs',\n",
       " 'cryptonite',\n",
       " 'cs_restaurants',\n",
       " 'cuad',\n",
       " 'curiosity_dialogs',\n",
       " 'daily_dialog',\n",
       " 'dane',\n",
       " 'danish_political_comments',\n",
       " 'dart',\n",
       " 'datacommons_factcheck',\n",
       " 'dbpedia_14',\n",
       " 'dbrd',\n",
       " 'deal_or_no_dialog',\n",
       " 'definite_pronoun_resolution',\n",
       " 'dengue_filipino',\n",
       " 'dialog_re',\n",
       " 'diplomacy_detection',\n",
       " 'disaster_response_messages',\n",
       " 'discofuse',\n",
       " 'discovery',\n",
       " 'disfl_qa',\n",
       " 'doc2dial',\n",
       " 'docred',\n",
       " 'doqa',\n",
       " 'dream',\n",
       " 'drop',\n",
       " 'duorc',\n",
       " 'dutch_social',\n",
       " 'dyk',\n",
       " 'e2e_nlg',\n",
       " 'e2e_nlg_cleaned',\n",
       " 'ecb',\n",
       " 'ecthr_cases',\n",
       " 'eduge',\n",
       " 'ehealth_kd',\n",
       " 'eitb_parcc',\n",
       " 'electricity_load_diagrams',\n",
       " 'eli5',\n",
       " 'eli5_category',\n",
       " 'emea',\n",
       " 'emo',\n",
       " 'dair-ai/emotion',\n",
       " 'emotone_ar',\n",
       " 'empathetic_dialogues',\n",
       " 'enriched_web_nlg',\n",
       " 'eraser_multi_rc',\n",
       " 'esnli',\n",
       " 'eth_py150_open',\n",
       " 'ethos',\n",
       " 'eu_regulatory_ir',\n",
       " 'eurlex',\n",
       " 'euronews',\n",
       " 'europa_eac_tm',\n",
       " 'europa_ecdc_tm',\n",
       " 'europarl_bilingual',\n",
       " 'event2Mind',\n",
       " 'evidence_infer_treatment',\n",
       " 'exams',\n",
       " 'factckbr',\n",
       " 'fake_news_english',\n",
       " 'fake_news_filipino',\n",
       " 'farsi_news',\n",
       " 'fashion_mnist',\n",
       " 'fever',\n",
       " 'few_rel',\n",
       " 'financial_phrasebank',\n",
       " 'finer',\n",
       " 'flores',\n",
       " 'flue',\n",
       " 'food101',\n",
       " 'fquad',\n",
       " 'freebase_qa',\n",
       " 'gap',\n",
       " 'gem',\n",
       " 'generated_reviews_enth',\n",
       " 'generics_kb',\n",
       " 'german_legal_entity_recognition',\n",
       " 'germaner',\n",
       " 'germeval_14',\n",
       " 'giga_fren',\n",
       " 'gigaword',\n",
       " 'glucose',\n",
       " 'glue',\n",
       " 'gnad10',\n",
       " 'go_emotions',\n",
       " 'gooaq',\n",
       " 'google_wellformed_query',\n",
       " 'grail_qa',\n",
       " 'great_code',\n",
       " 'greek_legal_code',\n",
       " 'guardian_authorship',\n",
       " 'gutenberg_time',\n",
       " 'hans',\n",
       " 'hansards',\n",
       " 'hard',\n",
       " 'harem',\n",
       " 'has_part',\n",
       " 'hate_offensive',\n",
       " 'hate_speech18',\n",
       " 'hate_speech_filipino',\n",
       " 'hate_speech_offensive',\n",
       " 'hate_speech_pl',\n",
       " 'hate_speech_portuguese',\n",
       " 'hatexplain',\n",
       " 'hausa_voa_ner',\n",
       " 'hausa_voa_topics',\n",
       " 'hda_nli_hindi',\n",
       " 'head_qa',\n",
       " 'health_fact',\n",
       " 'hebrew_projectbenyehuda',\n",
       " 'hebrew_sentiment',\n",
       " 'hebrew_this_world',\n",
       " 'hellaswag',\n",
       " 'cais/mmlu',\n",
       " 'hind_encorp',\n",
       " 'hindi_discourse',\n",
       " 'hippocorpus',\n",
       " 'hkcancor',\n",
       " 'hlgd',\n",
       " 'hope_edi',\n",
       " 'hotpot_qa',\n",
       " 'hover',\n",
       " 'hrenwac_para',\n",
       " 'hrwac',\n",
       " 'humicroedit',\n",
       " 'hybrid_qa',\n",
       " 'hyperpartisan_news_detection',\n",
       " 'iapp_wiki_qa_squad',\n",
       " 'id_clickbait',\n",
       " 'id_liputan6',\n",
       " 'id_nergrit_corpus',\n",
       " 'id_newspapers_2018',\n",
       " 'id_panl_bppt',\n",
       " 'id_puisi',\n",
       " 'igbo_english_machine_translation',\n",
       " 'igbo_monolingual',\n",
       " 'igbo_ner',\n",
       " 'ilist',\n",
       " 'imdb',\n",
       " 'imdb_urdu_reviews',\n",
       " 'imppres',\n",
       " 'indic_glue',\n",
       " 'indonli',\n",
       " 'indonlp/indonlu',\n",
       " 'inquisitive_qg',\n",
       " 'interpress_news_category_tr',\n",
       " 'interpress_news_category_tr_lite',\n",
       " 'irc_disentangle',\n",
       " 'isixhosa_ner_corpus',\n",
       " 'isizulu_ner_corpus',\n",
       " 'iwslt2017',\n",
       " 'jeopardy',\n",
       " 'jfleg',\n",
       " 'jigsaw_toxicity_pred',\n",
       " 'jigsaw_unintended_bias',\n",
       " 'jnlpba',\n",
       " 'journalists_questions',\n",
       " 'kan_hope',\n",
       " 'kannada_news',\n",
       " 'kd_conv',\n",
       " 'kde4',\n",
       " 'kelm',\n",
       " 'kilt_tasks',\n",
       " 'kilt_wikipedia',\n",
       " 'kinnews_kirnews',\n",
       " 'klue',\n",
       " 'kor_3i4k',\n",
       " 'kor_hate',\n",
       " 'kor_ner',\n",
       " 'kor_nli',\n",
       " 'kor_nlu',\n",
       " 'kor_qpair',\n",
       " 'kor_sae',\n",
       " 'kor_sarcasm',\n",
       " 'labr',\n",
       " 'lama',\n",
       " 'lambada',\n",
       " 'large_spanish_corpus',\n",
       " 'laroseda',\n",
       " 'lc_quad',\n",
       " 'lener_br',\n",
       " 'lex_glue',\n",
       " 'liar',\n",
       " 'librispeech_asr',\n",
       " 'librispeech_lm',\n",
       " 'limit',\n",
       " 'lince',\n",
       " 'linnaeus',\n",
       " 'liveqa',\n",
       " 'lj_speech',\n",
       " 'lm1b',\n",
       " 'lst20',\n",
       " 'm_lama',\n",
       " 'mac_morpho',\n",
       " 'makhzan',\n",
       " 'masakhaner',\n",
       " 'math_dataset',\n",
       " 'math_qa',\n",
       " 'matinf',\n",
       " 'mbpp',\n",
       " 'mc4',\n",
       " 'mc_taco',\n",
       " 'md_gender_bias',\n",
       " 'mdd',\n",
       " 'med_hop',\n",
       " 'medal',\n",
       " 'medical_dialog',\n",
       " 'medical_questions_pairs',\n",
       " 'menyo20k_mt',\n",
       " 'meta_woz',\n",
       " 'metooma',\n",
       " 'metrec',\n",
       " 'miam',\n",
       " 'mkb',\n",
       " 'mkqa',\n",
       " 'mlqa',\n",
       " 'mlsum',\n",
       " 'mnist',\n",
       " 'mocha',\n",
       " 'moroco',\n",
       " 'movie_rationales',\n",
       " 'mrqa',\n",
       " 'ms_marco',\n",
       " 'ms_terms',\n",
       " 'msr_genomics_kbcomp',\n",
       " 'msr_sqa',\n",
       " 'msr_text_compression',\n",
       " 'msr_zhen_translation_parity',\n",
       " 'msra_ner',\n",
       " 'mt_eng_vietnamese',\n",
       " 'muchocine',\n",
       " 'multi_booked',\n",
       " 'multi_eurlex',\n",
       " 'multi_news',\n",
       " 'multi_nli',\n",
       " 'multi_nli_mismatch',\n",
       " 'multi_para_crawl',\n",
       " 'multi_re_qa',\n",
       " 'multi_woz_v22',\n",
       " 'multi_x_science_sum',\n",
       " 'multidoc2dial',\n",
       " 'multilingual_librispeech',\n",
       " 'mutual_friends',\n",
       " 'mwsc',\n",
       " 'myanmar_news',\n",
       " 'narrativeqa',\n",
       " 'narrativeqa_manual',\n",
       " 'natural_questions',\n",
       " 'ncbi_disease',\n",
       " 'nchlt',\n",
       " 'ncslgr',\n",
       " 'nell',\n",
       " 'neural_code_search',\n",
       " 'news_commentary',\n",
       " 'newsgroup',\n",
       " 'newsph',\n",
       " 'newsph_nli',\n",
       " 'newspop',\n",
       " 'newsqa',\n",
       " 'newsroom',\n",
       " 'nkjp-ner',\n",
       " 'nli_tr',\n",
       " 'nlu_evaluation_data',\n",
       " 'norec',\n",
       " 'norne',\n",
       " 'norwegian_ner',\n",
       " 'nq_open',\n",
       " 'nsmc',\n",
       " 'numer_sense',\n",
       " 'numeric_fused_head',\n",
       " 'oclar',\n",
       " 'offcombr',\n",
       " 'offenseval2020_tr',\n",
       " 'offenseval_dravidian',\n",
       " 'ofis_publik',\n",
       " 'ohsumed',\n",
       " 'ollie',\n",
       " 'omp',\n",
       " 'onestop_english',\n",
       " 'onestop_qa',\n",
       " 'open_subtitles',\n",
       " 'openai_humaneval',\n",
       " 'openbookqa',\n",
       " 'openslr',\n",
       " 'openwebtext',\n",
       " 'opinosis',\n",
       " 'opus100',\n",
       " 'opus_books',\n",
       " 'opus_dgt',\n",
       " 'opus_dogc',\n",
       " 'opus_elhuyar',\n",
       " 'opus_euconst',\n",
       " 'opus_finlex',\n",
       " 'opus_fiskmo',\n",
       " 'opus_gnome',\n",
       " 'opus_infopankki',\n",
       " 'opus_memat',\n",
       " 'opus_montenegrinsubs',\n",
       " 'opus_openoffice',\n",
       " 'opus_paracrawl',\n",
       " 'opus_rf',\n",
       " 'opus_tedtalks',\n",
       " 'opus_ubuntu',\n",
       " 'opus_wikipedia',\n",
       " 'opus_xhosanavy',\n",
       " 'orange_sum',\n",
       " 'oscar',\n",
       " 'para_crawl',\n",
       " 'para_pat',\n",
       " 'parsinlu_reading_comprehension',\n",
       " 'pass',\n",
       " 'paws-x',\n",
       " 'paws',\n",
       " 'pec',\n",
       " 'allenai/peer_read',\n",
       " 'peoples_daily_ner',\n",
       " 'per_sent',\n",
       " 'persian_ner',\n",
       " 'pg19',\n",
       " 'php',\n",
       " 'etalab-ia/piaf',\n",
       " 'pib',\n",
       " 'piqa',\n",
       " 'pn_summary',\n",
       " 'poem_sentiment',\n",
       " 'polemo2',\n",
       " 'poleval2019_cyberbullying',\n",
       " 'poleval2019_mt',\n",
       " 'polsum',\n",
       " 'polyglot_ner',\n",
       " 'prachathai67k',\n",
       " 'pragmeval',\n",
       " 'proto_qa',\n",
       " 'psc',\n",
       " 'ptb_text_only',\n",
       " 'pubmed',\n",
       " 'pubmed_qa',\n",
       " 'py_ast',\n",
       " 'qa4mre',\n",
       " 'qa_srl',\n",
       " 'qa_zre',\n",
       " 'qangaroo',\n",
       " 'qanta',\n",
       " 'qasc',\n",
       " 'allenai/qasper',\n",
       " 'qed',\n",
       " 'qed_amara',\n",
       " 'quac',\n",
       " 'quail',\n",
       " 'quarel',\n",
       " 'quartz',\n",
       " 'quora',\n",
       " 'quoref',\n",
       " 'race',\n",
       " 're_dial',\n",
       " 'reasoning_bg',\n",
       " 'recipe_nlg',\n",
       " 'reclor',\n",
       " 'red_caps',\n",
       " 'webis/tldr-17',\n",
       " 'reddit_tifu',\n",
       " 'refresd',\n",
       " 'reuters21578',\n",
       " 'riddle_sense',\n",
       " 'ro_sent',\n",
       " 'ro_sts',\n",
       " 'ro_sts_parallel',\n",
       " 'roman_urdu',\n",
       " 'ronec',\n",
       " 'ropes',\n",
       " 'rotten_tomatoes',\n",
       " 'RussianNLP/russian_super_glue',\n",
       " 'allenai/s2orc',\n",
       " 'samsum',\n",
       " 'sanskrit_classic',\n",
       " 'saudinewsnet',\n",
       " 'sberquad',\n",
       " 'scan',\n",
       " 'scb_mt_enth_2020',\n",
       " 'scene_parse_150',\n",
       " 'schema_guided_dstc8',\n",
       " 'allenai/scicite',\n",
       " 'scielo',\n",
       " 'scientific_papers',\n",
       " 'allenai/scifact',\n",
       " 'sciq',\n",
       " 'scitail',\n",
       " 'allenai/scitldr',\n",
       " 'search_qa',\n",
       " 'sede',\n",
       " 'selqa',\n",
       " 'sem_eval_2010_task_8',\n",
       " 'sem_eval_2014_task_1',\n",
       " 'sem_eval_2018_task_1',\n",
       " 'sem_eval_2020_task_11',\n",
       " 'sent_comp',\n",
       " 'senti_lex',\n",
       " 'senti_ws',\n",
       " 'sentiment140',\n",
       " 'sepedi_ner',\n",
       " 'sesotho_ner_corpus',\n",
       " 'setimes',\n",
       " 'setswana_ner_corpus',\n",
       " 'sharc',\n",
       " 'sharc_modified',\n",
       " 'sick',\n",
       " 'silicone',\n",
       " 'simple_questions_v2',\n",
       " 'siswati_ner_corpus',\n",
       " 'smartdata',\n",
       " 'sms_spam',\n",
       " 'snips_built_in_intents',\n",
       " 'snli',\n",
       " 'snow_simplified_japanese_corpus',\n",
       " 'so_stacksample',\n",
       " 'social_bias_frames',\n",
       " 'social_i_qa',\n",
       " 'sofc_materials_articles',\n",
       " 'sogou_news',\n",
       " 'spanish_billion_words',\n",
       " 'spc',\n",
       " 'species_800',\n",
       " 'speech_commands',\n",
       " 'spider',\n",
       " 'squad',\n",
       " 'squad_adversarial',\n",
       " 'squad_es',\n",
       " 'squad_it',\n",
       " 'squad_kor_v1',\n",
       " 'squad_kor_v2',\n",
       " 'squad_v1_pt',\n",
       " 'squad_v2',\n",
       " 'squadshifts',\n",
       " 'srwac',\n",
       " 'sst',\n",
       " 'stereoset',\n",
       " 'story_cloze',\n",
       " 'stsb_mt_sv',\n",
       " 'stsb_multi_mt',\n",
       " 'style_change_detection',\n",
       " 'subjqa',\n",
       " 'super_glue',\n",
       " 'superb',\n",
       " 'svhn',\n",
       " 'swag',\n",
       " 'swahili',\n",
       " 'swahili_news',\n",
       " 'swda',\n",
       " 'swedish_medical_ner',\n",
       " 'swedish_ner_corpus',\n",
       " 'swedish_reviews',\n",
       " 'rcds/swiss_judgment_prediction',\n",
       " 'tab_fact',\n",
       " 'tamilmixsentiment',\n",
       " 'tanzil',\n",
       " 'tapaco',\n",
       " 'tashkeela',\n",
       " 'taskmaster1',\n",
       " 'taskmaster2',\n",
       " 'taskmaster3',\n",
       " 'tatoeba',\n",
       " 'ted_hrlr',\n",
       " 'ted_iwlst2013',\n",
       " 'ted_multi',\n",
       " 'ted_talks_iwslt',\n",
       " 'telugu_books',\n",
       " 'telugu_news',\n",
       " 'tep_en_fa_para',\n",
       " 'text2log',\n",
       " 'thai_toxicity_tweet',\n",
       " 'thainer',\n",
       " 'thaiqa_squad',\n",
       " 'thaisum',\n",
       " 'EleutherAI/pile',\n",
       " 'the_pile_books3',\n",
       " 'the_pile_openwebtext2',\n",
       " 'the_pile_stack_exchange',\n",
       " 'tilde_model',\n",
       " 'time_dial',\n",
       " 'times_of_india_news_headlines',\n",
       " 'timit_asr',\n",
       " 'tiny_shakespeare',\n",
       " 'tlc',\n",
       " 'tmu_gfm_dataset',\n",
       " 'told-br',\n",
       " 'totto',\n",
       " 'trec',\n",
       " 'trivia_qa',\n",
       " 'tsac',\n",
       " 'ttc4900',\n",
       " 'tunizi',\n",
       " 'tuple_ie',\n",
       " 'turk',\n",
       " 'turkic_xwmt',\n",
       " 'turkish_movie_sentiment',\n",
       " 'turkish_ner',\n",
       " 'turkish_product_reviews',\n",
       " 'turkish_shrinked_ner',\n",
       " 'turku_ner_corpus',\n",
       " 'tweet_eval',\n",
       " 'tweet_qa',\n",
       " 'tweets_ar_en_parallel',\n",
       " 'tweets_hate_speech_detection',\n",
       " 'twi_text_c3',\n",
       " 'twi_wordsim353',\n",
       " 'tydiqa',\n",
       " 'ubuntu_dialogs_corpus',\n",
       " 'udhr',\n",
       " 'um005',\n",
       " 'un_ga',\n",
       " 'un_multi',\n",
       " 'un_pc',\n",
       " 'universal_dependencies',\n",
       " 'universal_morphologies',\n",
       " 'urdu_fake_news',\n",
       " 'urdu_sentiment_corpus',\n",
       " 'vctk',\n",
       " 'vivos',\n",
       " 'web_nlg',\n",
       " 'web_of_science',\n",
       " 'web_questions',\n",
       " 'weibo_ner',\n",
       " 'wi_locness',\n",
       " 'wider_face',\n",
       " 'wiki40b',\n",
       " 'wiki_asp',\n",
       " 'wiki_atomic_edits',\n",
       " 'wiki_auto',\n",
       " 'wiki_bio',\n",
       " 'wiki_dpr',\n",
       " 'wiki_hop',\n",
       " 'wiki_lingua',\n",
       " 'wiki_movies',\n",
       " 'wiki_qa',\n",
       " 'wiki_qa_ar',\n",
       " 'wiki_snippets',\n",
       " 'wiki_source',\n",
       " 'wiki_split',\n",
       " 'wiki_summary',\n",
       " 'wikiann',\n",
       " 'wikicorpus',\n",
       " 'wikihow',\n",
       " 'wikipedia',\n",
       " 'wikisql',\n",
       " 'wikitext',\n",
       " 'wikitext_tl39',\n",
       " 'wili_2018',\n",
       " 'wino_bias',\n",
       " 'winograd_wsc',\n",
       " 'winogrande',\n",
       " 'wiqa',\n",
       " 'wisesight1000',\n",
       " 'wisesight_sentiment',\n",
       " 'wmt14',\n",
       " 'wmt15',\n",
       " 'wmt16',\n",
       " 'wmt17',\n",
       " 'wmt18',\n",
       " 'wmt19',\n",
       " 'wmt20_mlqe_task1',\n",
       " 'wmt20_mlqe_task2',\n",
       " 'wmt20_mlqe_task3',\n",
       " 'wmt_t2t',\n",
       " 'wnut_17',\n",
       " 'wongnai_reviews',\n",
       " 'woz_dialogue',\n",
       " 'wrbsc',\n",
       " 'x_stance',\n",
       " 'xcopa',\n",
       " 'xcsr',\n",
       " 'xed_en_fi',\n",
       " 'xglue',\n",
       " 'xnli',\n",
       " 'xor_tydi_qa',\n",
       " 'xquad',\n",
       " 'xquad_r',\n",
       " 'xsum',\n",
       " 'xsum_factuality',\n",
       " 'xtreme',\n",
       " 'yahoo_answers_qa',\n",
       " 'yahoo_answers_topics',\n",
       " 'yelp_polarity',\n",
       " 'yelp_review_full',\n",
       " 'yoruba_bbc_topics',\n",
       " 'yoruba_gv_ner',\n",
       " 'yoruba_text_c3',\n",
       " 'yoruba_wordsim353',\n",
       " 'youtube_caption_corrections',\n",
       " 'zest',\n",
       " '0n1xus/codexglue',\n",
       " '0n1xus/pytorrent-standalone',\n",
       " 'AConsApart/anime_subtitles_DialoGPT',\n",
       " 'AHussain0418/day2_data',\n",
       " 'AHussain0418/day4data',\n",
       " 'AHussain0418/demo_data',\n",
       " 'AI-Sweden/SuperLim',\n",
       " 'AI-it/khs_service_test',\n",
       " 'AI-it/korean-hate-speech',\n",
       " 'ARKseal/YFCC14M_subset_webdataset',\n",
       " 'ARTeLab/fanpage',\n",
       " 'ARTeLab/ilpost',\n",
       " 'ARTeLab/mlsum-it',\n",
       " 'ASCCCCCCCC/amazon_zh',\n",
       " 'ASCCCCCCCC/amazon_zh_simple',\n",
       " 'Abdo1Kamr/Arabic_Hadith',\n",
       " 'Abirate/code_net_dataset',\n",
       " 'Abirate/code_net_dev_dataset',\n",
       " 'Abirate/code_net_test_final_dataset',\n",
       " 'Abirate/english_quotes',\n",
       " 'Abirate/french_book_reviews',\n",
       " 'AdWeeb/DravidianMT',\n",
       " 'Adnan/Urdu_News_Headlines',\n",
       " 'AhmadSawal/qa',\n",
       " 'AhmedSSoliman/CoNaLa',\n",
       " 'Aisha/BAAD16',\n",
       " 'Aisha/BAAD6',\n",
       " 'Akila/ForgottenRealmsWikiDataset',\n",
       " 'Akshith/aa',\n",
       " 'Akshith/g_rock',\n",
       " 'Akshith/test',\n",
       " 'adorkin/extended_tweet_emojis',\n",
       " 'AlekseyKorshuk/comedy-scripts',\n",
       " 'AlekseyKorshuk/horror-scripts',\n",
       " 'AlexMaclean/all-deletion-compressions',\n",
       " 'AlexMaclean/wikipedia-deletion-compressions',\n",
       " 'AlexZapolskii/zapolskii-amazon',\n",
       " 'AlgoveraAI/CryptoPunks',\n",
       " 'Aliseyfi/event_token_type',\n",
       " 'Alvenir/nst-da-16khz',\n",
       " 'AndrewMcDowell/de_corpora_parliament_processed',\n",
       " 'Annabelleabbott/real-fake-news-workshop',\n",
       " 'Annielytics/DoctorsNotes',\n",
       " 'Anurag-Singh-creator/task',\n",
       " 'Anurag-Singh-creator/tasks',\n",
       " 'ApiInferenceTest/asr_dummy',\n",
       " 'Arnold/hausa_common_voice',\n",
       " 'AryanLala/autonlp-data-Scientific_Title_Generator',\n",
       " 'Atsushi/fungi_diagnostic_chars_comparison_japanese',\n",
       " 'Atsushi/fungi_indexed_mycological_papers_japanese',\n",
       " 'Atsushi/fungi_trait_circus_database',\n",
       " 'Avishekavi/Avi',\n",
       " 'BSC-LT/SQAC',\n",
       " 'BSC-LT/ancora-ca-ner',\n",
       " 'BSC-LT/sts-ca',\n",
       " 'BSC-LT/tecla',\n",
       " 'BSC-LT/viquiquad',\n",
       " 'BSC-LT/xquad-ca',\n",
       " 'Babelscape/rebel-dataset',\n",
       " 'Babelscape/wikineural',\n",
       " 'BatuhanYilmaz/github-issues',\n",
       " 'Baybars/parla_text_corpus',\n",
       " 'BeIR/beir-corpus',\n",
       " 'BeIR/beir',\n",
       " 'Lacito/pangloss',\n",
       " 'Binbin/my_dataset',\n",
       " 'BlakesOrb6/Fred-Flintstone',\n",
       " 'Bosio/pacman',\n",
       " 'Bosio/pacman_descriptions',\n",
       " 'BritishLibraryLabs/EThOS-PhD-metadata',\n",
       " 'CAGER/rick',\n",
       " 'CALM/arwiki',\n",
       " 'CAiRE/ASCEND',\n",
       " 'CShorten/KerasBERT',\n",
       " 'ChadxxxxHall/Inter-vision',\n",
       " 'Champion/vpc2020_clear_anon_speech',\n",
       " 'Check/a_re_gi',\n",
       " 'Check/region_1',\n",
       " 'Check/region_2',\n",
       " 'Check/region_3',\n",
       " 'Check/region_4',\n",
       " 'Check/region_5',\n",
       " 'Check/region_6',\n",
       " 'Check/region_7',\n",
       " 'Check/region_8',\n",
       " 'Check/region_9',\n",
       " 'Check/regions',\n",
       " 'Check/vverify',\n",
       " 'Cheranga/test',\n",
       " 'ChristophSchuhmann/MS_COCO_2017_URL_TEXT',\n",
       " 'Chun/dataset',\n",
       " 'Chuu/Vhh',\n",
       " 'CodedotAI/code-clippy-tfrecords',\n",
       " 'CodedotAI/code_clippy',\n",
       " 'CodedotAI/code_clippy_github',\n",
       " 'Crives/haha',\n",
       " 'Cropinky/flatearther',\n",
       " 'Cropinky/rap_lyrics_english',\n",
       " 'Cropinky/wow_fishing_bobber',\n",
       " 'Cyberfish/pos_tagger',\n",
       " 'Cyberfish/text_error_correction',\n",
       " 'CyranoB/polarity',\n",
       " 'DDSC/angry-tweets',\n",
       " 'DDSC/dkhate',\n",
       " 'DDSC/europarl',\n",
       " 'DDSC/lcc',\n",
       " 'DDSC/partial-danish-gigaword-no-twitter',\n",
       " 'DDSC/reddit-da-asr-preprocessed',\n",
       " 'DDSC/reddit-da',\n",
       " 'DDSC/twitter-sent',\n",
       " 'DELith/github-issues',\n",
       " 'DSCI511G1/COP26_Energy_Transition_Tweets',\n",
       " 'DanL/scientific-challenges-and-directions-dataset',\n",
       " 'Daniele/dante-corpus',\n",
       " 'Darren/data',\n",
       " 'Datatang/accented_english',\n",
       " 'Datatang/accented_mandarin',\n",
       " 'Datatang/chinese_dialect',\n",
       " 'Datatang/mandarin_chinese',\n",
       " 'Datatang/mixed_speech_chinese_english',\n",
       " 'Datatang/multi_language',\n",
       " 'Datatang/multi_language_conversation',\n",
       " 'Davlan/conll2003_de_noMISC',\n",
       " 'Davlan/conll2003_noMISC',\n",
       " 'Davlan/masakhanerV1',\n",
       " 'DelgadoPanadero/Pokemon',\n",
       " 'DeskDown/ALTDataset',\n",
       " 'DeskDown/ALTDataset_en-to-fil-vi-id-ms-ja-khm',\n",
       " 'DiFronzo/Human_Activity_Recognition',\n",
       " 'Dmitriy612/1',\n",
       " 'DoctorSlimm/yipee',\n",
       " 'Doohae/klue-mrc-bm25',\n",
       " 'Doohae/modern_music_re',\n",
       " 'DoyyingFace/github-embeddings-doy',\n",
       " 'DoyyingFace/github-issues-doy',\n",
       " 'DrishtiSharma/as_opus100_processed',\n",
       " 'DrishtiSharma/bg_opus100_processed',\n",
       " 'DrishtiSharma/br_opus100_processed',\n",
       " 'DrishtiSharma/hi_opus100_processed',\n",
       " 'DrishtiSharma/kk_opus100_processed',\n",
       " 'DrishtiSharma/mr_opus100_processed',\n",
       " 'DrishtiSharma/or_opus100_processed',\n",
       " 'DrishtiSharma/sl_opus100_processed',\n",
       " 'DrishtiSharma/sr_opus100_processed',\n",
       " 'Dumiiii/common-voice-romaniarss',\n",
       " 'EMBO/biolang',\n",
       " 'EMBO/sd-nlp',\n",
       " 'ESZER/H',\n",
       " 'Emanuel/UD_Portuguese-Bosque',\n",
       " 'Emma121/aaaaa',\n",
       " 'Emma121/testtest',\n",
       " 'Enes3774/data',\n",
       " 'Exr0n/wiki-entity-similarity',\n",
       " 'Eymen3455/xsum_tr',\n",
       " 'FIG-Loneliness/FIG-Loneliness',\n",
       " 'FL33TW00D/test-dataset',\n",
       " 'FRTNX/cosuju',\n",
       " 'FRTNX/worldbank-projects',\n",
       " 'Felix-ML/quoteli3',\n",
       " 'Finnish-NLP/mc4_fi_cleaned',\n",
       " 'Firoj/HumAID',\n",
       " 'Francois/futures_es',\n",
       " 'Fraser/mnist-text-default',\n",
       " 'Fraser/mnist-text-no-spaces',\n",
       " 'Fraser/mnist-text-small',\n",
       " 'Fraser/dream-coder',\n",
       " 'Fraser/python-lines',\n",
       " 'Fraser/python-state-changes',\n",
       " 'Fraser/short-jokes',\n",
       " 'Fraser/wiki_sentences',\n",
       " 'GEM/ART',\n",
       " 'GEM/BiSECT',\n",
       " 'GEM/CrossWOZ',\n",
       " 'GEM/OrangeSum',\n",
       " 'GEM/RiSAWOZ',\n",
       " 'GEM/RotoWire_English-German',\n",
       " 'GEM/SIMPITIKI',\n",
       " 'GEM/SciDuet',\n",
       " 'GEM/Taskmaster',\n",
       " 'GEM/cochrane-simplification',\n",
       " 'GEM/common_gen',\n",
       " 'GEM/conversational_weather',\n",
       " 'GEM/cs_restaurants',\n",
       " 'GEM/dart',\n",
       " 'GEM/dstc10_track2_task2',\n",
       " 'GEM/e2e_nlg',\n",
       " 'GEM/indonlg',\n",
       " 'GEM/mlb_data_to_text',\n",
       " 'GEM/mlsum',\n",
       " 'GEM/opusparcus',\n",
       " 'GEM/references',\n",
       " 'GEM/schema_guided_dialog',\n",
       " 'GEM/sportsett_basketball',\n",
       " 'GEM/squad_v2',\n",
       " 'GEM/surface_realisation_st_2020',\n",
       " 'GEM/totto',\n",
       " 'GEM/turku_hockey_data2text',\n",
       " 'GEM/turku_paraphrase_corpus',\n",
       " 'GEM-submissions/v1-outputs-and-scores',\n",
       " 'GEM/viggo',\n",
       " 'GEM/web_nlg',\n",
       " 'GEM/wiki_auto_asset_turk',\n",
       " 'GEM/wiki_cat_sum',\n",
       " 'GEM/wiki_lingua',\n",
       " 'GEM/xlsum',\n",
       " 'GEM/xsum',\n",
       " 'GEM-submissions/GEM__bart_base_schema_guided_dialog__1645547915',\n",
       " 'GEM-submissions/Leo__bart-large__1645784880',\n",
       " 'GEM-submissions/Leo__mbart-large-cc25__1645802644',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1645558682',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1645559101',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1645800191',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1646049378',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1646049424',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1646049601',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1646049876',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1646050898',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1646051364',\n",
       " 'GEM-submissions/lewtun__hugging-face-test-t5-base.outputs.json-36bf2a59__1646052073',\n",
       " 'GEM-submissions/lewtun__this-is-a-test__1646052811',\n",
       " 'GEM-submissions/lewtun__this-is-a-test__1646230987',\n",
       " 'GEM-submissions/ratishsp',\n",
       " 'GEM-submissions/submission-scores',\n",
       " 'GV05/shlomit_speech',\n",
       " 'Gabriel/quora_swe',\n",
       " 'GalacticAI/Noirset',\n",
       " 'Gauravadlakha1509/new_one',\n",
       " 'GeoffVdr/cv8_trainval_processed',\n",
       " 'GonzaloA/fake_news',\n",
       " 'Graphcore/gqa-lxmert',\n",
       " 'Graphcore/gqa',\n",
       " 'Graphcore/vqa-lxmert',\n",
       " 'Graphcore/vqa',\n",
       " 'Graphcore/wikipedia-bert-128',\n",
       " 'Graphcore/wikipedia-bert-512',\n",
       " 'GroNLP/ik-nlp-22_pestyle',\n",
       " 'GroNLP/ik-nlp-22_slp',\n",
       " 'GroNLP/ik-nlp-22_transqe',\n",
       " 'GroNLP/ik-nlp-22_winemag',\n",
       " 'Gwangho/NCBI-Sars-Cov-2',\n",
       " 'HHousen/ParaSCI',\n",
       " 'HHousen/msrp',\n",
       " 'HHousen/quora',\n",
       " 'HUPD/hupd',\n",
       " 'Halilyesilceng/autonlp-data-nameEntityRecognition',\n",
       " 'HarleyQ/WitcherDialogue',\n",
       " 'HarrisDePerceptron/sv_corpora_parliament_processed',\n",
       " 'HarrisDePerceptron/ur_corpora_pib',\n",
       " 'Harveenchadha/bol-models',\n",
       " 'Harveenchadha/indic-voice',\n",
       " 'HarveyBWest/mybot',\n",
       " 'Hellisotherpeople/DebateSum',\n",
       " 'Helsinki-NLP/tatoeba_mt',\n",
       " 'HenryAI/KerasAPIReference.txt',\n",
       " 'HenryAI/KerasBERTv1-Data',\n",
       " 'HenryAI/KerasCodeExamples.txt',\n",
       " 'HenryAI/KerasDeveloperGuides.txt',\n",
       " 'Huertas97/autonlp-data-mami-semeval-20-21',\n",
       " 'Husain/intent-classification-en-fr',\n",
       " 'IFSTalfredoswald/MBTI',\n",
       " 'Iftoo95/Arabic_Sentiment_and_Topics',\n",
       " 'IlyaGusev/gazeta',\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import list_datasets\n",
    "list_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03650d1f",
   "metadata": {},
   "source": [
    "### We load the dataset with 3453 entires where for each entry of labels, at least 75% of the annotators agree with the lable.\n",
    "\n",
    "#### label 0 = Negative\n",
    "#### label 1 = Neutral\n",
    "#### label 2 = Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3b83a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (/Users/thomasli/.cache/huggingface/datasets/financial_phrasebank/sentences_75agree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbe21fa6633409faf2e5dc1e03d4b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "fin_news = load_dataset('financial_phrasebank', 'sentences_75agree')\n",
    "fin_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b667a3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': ['According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .',\n",
       "  'With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .',\n",
       "  \"For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .\"],\n",
       " 'label': [1, 2, 2]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_news['train'][0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc52f0a1",
   "metadata": {},
   "source": [
    "### To train the entire dataset would take hours, so to reduce the time, I shrunk the dataset size to 800 entires. And now, to create the test and validation set.\n",
    "\n",
    "I will take 640 as my training dataset and put 160 towards the validation+test dataset. The validation dataset helps me to see how well the model is training, whether it's overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcd7d9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/thomasli/.cache/huggingface/datasets/financial_phrasebank/sentences_75agree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141/cache-f7ffdc83e59ee304.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'label'],\n",
       "    num_rows: 800\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_news['train'] = fin_news['train'].shuffle(seed=1).select(range(800))\n",
    "fin_news['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75bc9057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 640\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 160\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_news_train_validation = fin_news['train'].train_test_split(train_size=0.8)\n",
    "fin_news_test_valid = fin_news_train_validation['test'].train_test_split(train_size=0.5)\n",
    "fin_news_train_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d9c8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_news_test_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "415933b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_news_test_valid['validation'] = fin_news_test_valid.pop('train')\n",
    "fin_news_test_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d208de4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 640\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_news_train_validation.update(fin_news_test_valid)\n",
    "fin_news_train_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc181ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 640\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_news.update(fin_news_train_validation)\n",
    "fin_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b422f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': ['Conference Call To participate via a conference call , please dial in 5-10 minutes before the beginning of the event : +44 0 20 7162 0025 Europe or +1 334-á323-á6201 USA .',\n",
       "  \"Tekla Structures 16 is ` all about you and your team ' and compatible with the Windows 7 operating system .\",\n",
       "  \"The group 's net sales in 2007 were EUR683 .6 m.\"],\n",
       " 'label': [1, 1, 1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_news['train'][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9f727ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': ['Finnish silicon wafer technology company Okmetic Oyj ( OMX Helsinki : OKM1V ) reported on Thursday ( 7 August ) an operating profit of EUR5 .3 m for the period January-June 2008 , up from EUR3 .3 m in the corresponding period in 2007 .',\n",
       "  'The implementation of the deal is subject to the approval by the Finnish Competition Authority .',\n",
       "  'All depends on financing .'],\n",
       " 'label': [2, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_news['test'][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11549d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': ['The plan is estimated to generate some EUR 5 million ( USD 6.5 m ) in cost savings on an annual basis .',\n",
       "  'Operating profit in the fourth quarter went down to EUR3m from EUR4 .2 m for the corresponding period of 2009 as it included costs of growth projects .',\n",
       "  'Earnings per share ( EPS ) amounted to a loss of to EUR0 .06 .'],\n",
       " 'label': [2, 0, 0]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_news['validation'][0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59855b4",
   "metadata": {},
   "source": [
    "### Overview of Financial News Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5471c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('max_colwidth', 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f335e612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>In the third quarter of fiscal 2008 Efore swung to a net loss of EUR 400,000 versus a net profit of EUR 200,000 for the corresponding period of fiscal 2007 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>The second-quarter net sales are expected to be on par with the first quarter of 2009 .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>With this appointment Kaupthing Bank aims to further co-ordinate Capital Markets activities within the Group and to improve the overall service to clients .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Finnlines estimated in its annual general meeting that 2008 will be financially a tough year due to large investments .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Established in 1987 , the SRV Group is a private Finnish construction concern with operations in Finland , the Baltic countries and Russia .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Total operating revenue grew by 27.6 % year-on-year to EUR61m .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Earnings per share EPS in 2005 decreased to EUR0 .66 from EUR1 .15 in 2004 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>CapMan Plc Press Release 31 March 2008 Jukka Ruuska , President of the OMX Nordic Exchanges and the Stockholm Stock Exchange , will transfer to CapMan effective no later than September 2008 .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>The board machine , which will have a wire width of 6.25 m and a design speed of 900 m-min , will produce close to 1,400 tonnes of folding boxboard per day .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Suominen Corporation estimates that the cost-cutting program that started in autumn 2005 , higher sales prices , and expected growth in volume of Wet Wipes , will make the company 's operations more profitable .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                sentence  \\\n",
       "132                                                        In the third quarter of fiscal 2008 Efore swung to a net loss of EUR 400,000 versus a net profit of EUR 200,000 for the corresponding period of fiscal 2007 .   \n",
       "622                                                                                                                              The second-quarter net sales are expected to be on par with the first quarter of 2009 .   \n",
       "525                                                         With this appointment Kaupthing Bank aims to further co-ordinate Capital Markets activities within the Group and to improve the overall service to clients .   \n",
       "289                                                                                              Finnlines estimated in its annual general meeting that 2008 will be financially a tough year due to large investments .   \n",
       "82                                                                          Established in 1987 , the SRV Group is a private Finnish construction concern with operations in Finland , the Baltic countries and Russia .   \n",
       "404                                                                                                                                                      Total operating revenue grew by 27.6 % year-on-year to EUR61m .   \n",
       "449                                                                                                                                         Earnings per share EPS in 2005 decreased to EUR0 .66 from EUR1 .15 in 2004 .   \n",
       "631                      CapMan Plc Press Release 31 March 2008 Jukka Ruuska , President of the OMX Nordic Exchanges and the Stockholm Stock Exchange , will transfer to CapMan effective no later than September 2008 .   \n",
       "626                                                        The board machine , which will have a wire width of 6.25 m and a design speed of 900 m-min , will produce close to 1,400 tonnes of folding boxboard per day .   \n",
       "380  Suominen Corporation estimates that the cost-cutting program that started in autumn 2005 , higher sales prices , and expected growth in volume of Wet Wipes , will make the company 's operations more profitable .   \n",
       "\n",
       "     label  \n",
       "132      0  \n",
       "622      1  \n",
       "525      2  \n",
       "289      0  \n",
       "82       1  \n",
       "404      2  \n",
       "449      0  \n",
       "631      1  \n",
       "626      1  \n",
       "380      2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_news.set_format('pandas')\n",
    "df = fin_news['train'][:]\n",
    "df.sample(frac=1 ,random_state=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15371cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Conference Call To participate via a conference call , please dial in 5-10 minutes before the beginning of the event : +44 0 20 7162 0025 Europe or +1 334-á323-á6201 USA .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e6588a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    403\n",
       "2    159\n",
       "0     78\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d4d9eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Words per review\"] = df[\"sentence\"].str.split().apply(len)\n",
    "df.boxplot(\"Words per review\", by=\"label\", grid=False, showfliers=False,\n",
    "           color=\"black\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "315d4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we are done working with the dataset in the pandas format, reset it.\n",
    "fin_news.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ba49b6",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "\n",
    "Now to tokenize each sentences so that we can convert each words to corresponding ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "964fb45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/640 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 640\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"sentence\"], padding=True, truncation=True)\n",
    "\n",
    "# The map functions uses apache arrow and make sure that the dataset is stored in the hard disk and only the datas\n",
    "# we are working with are used so we don't overload our RAM.\n",
    "fin_news_encoded = fin_news.map(tokenize_function, batched=True, batch_size=None)\n",
    "fin_news_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a4bedbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 'Conference Call To participate via a conference call , please dial in 5-10 minutes before the beginning of the event : +44 0 20 7162 0025 Europe or +1 334-á323-á6201 USA .', 'label': 1, 'input_ids': [101, 3047, 7268, 1706, 4868, 2258, 170, 3511, 1840, 117, 4268, 17693, 1107, 126, 118, 1275, 1904, 1196, 1103, 2150, 1104, 1103, 1856, 131, 116, 3140, 121, 1406, 5729, 1545, 1477, 3135, 17600, 1980, 1137, 116, 122, 3081, 1527, 118, 247, 17101, 1495, 118, 247, 1545, 10973, 1475, 3066, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'sentence': 'Finnish silicon wafer technology company Okmetic Oyj ( OMX Helsinki : OKM1V ) reported on Thursday ( 7 August ) an operating profit of EUR5 .3 m for the period January-June 2008 , up from EUR3 .3 m in the corresponding period in 2007 .', 'label': 2, 'input_ids': [101, 6389, 22818, 20049, 6732, 2815, 1419, 23330, 11006, 1596, 152, 1183, 3361, 113, 152, 22941, 12471, 131, 10899, 2107, 1475, 2559, 114, 2103, 1113, 9170, 113, 128, 1360, 114, 1126, 3389, 5022, 1104, 7270, 2069, 1571, 119, 124, 182, 1111, 1103, 1669, 1356, 118, 1340, 1369, 117, 1146, 1121, 7270, 2069, 1495, 119, 124, 182, 1107, 1103, 7671, 1669, 1107, 1384, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(fin_news_encoded['train'][0])\n",
    "print(fin_news_encoded['test'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e4cc1",
   "metadata": {},
   "source": [
    "There are a lot of zeros above in the input ids because the tokenizer automatically implement a method called padding to ensure every single sample has the same length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a2369e",
   "metadata": {},
   "source": [
    "### Tiny Finance Dataset for Transfer Learning\n",
    "\n",
    "Now that we have our tokenized dataset, we want to pass it through a bert model.\n",
    "\n",
    "Now, we are adding a classification head on top of the pretrained model with 3 classes/labels. We will then be training the classification head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "447f0873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6473bc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 12:55:53.105366: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# torch.device for if we can runt it with gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_labels = 3\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(checkpoint, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f21ef2",
   "metadata": {},
   "source": [
    "Now, I want to take a small sample of data, train with that, then see the output. If I'm happy with the output, then I will train the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30cf35a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/60 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 60\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "tiny_fin = DatasetDict()\n",
    "tiny_fin['train'] = fin_news['train'].shuffle(seed=1).select(range(60))\n",
    "tiny_fin['validation'] = fin_news['validation'].shuffle(seed=1).select(range(10))\n",
    "tiny_fin['test'] = fin_news['test'].shuffle(seed=1).select(range(10))\n",
    "\n",
    "tiny_fin_encoded = tiny_fin.map(tokenize_function, batched=True, batch_size=None)\n",
    "tiny_fin_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeebff88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=0,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_backend=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_steps=None,\n",
       "evaluation_strategy=epoch,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=every_save,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=2e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=0,\n",
       "log_level=error,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=bert-base-cased-finetuned-tiny-fin-news/runs/Jul04_12-55-59_Thomass-MBP,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=7,\n",
       "logging_strategy=steps,\n",
       "lr_scheduler_type=linear,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "no_cuda=False,\n",
       "num_train_epochs=2,\n",
       "optim=adamw_torch,\n",
       "optim_args=None,\n",
       "output_dir=bert-base-cased-finetuned-tiny-fin-news,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=8,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=['tensorboard'],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=bert-base-cased-finetuned-tiny-fin-news,\n",
       "save_on_each_node=False,\n",
       "save_safetensors=False,\n",
       "save_steps=500,\n",
       "save_strategy=steps,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "sharded_ddp=[],\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.01,\n",
       "xpu_backend=None,\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 8\n",
    "logging_steps = len(tiny_fin_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{checkpoint}-finetuned-tiny-fin-news\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=2,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  log_level=\"error\",\n",
    "                                  optim='adamw_torch'\n",
    "                                  )\n",
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08da5eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.170900</td>\n",
       "      <td>1.106294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.946900</td>\n",
       "      <td>1.077049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer = Trainer(model=model, \n",
    "                  args=training_args, \n",
    "                  train_dataset=tiny_fin_encoded[\"train\"],\n",
    "                  eval_dataset=tiny_fin_encoded[\"validation\"],\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fa785cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.29440004,  0.22680606, -0.462095  ],\n",
       "       [-0.27299467,  0.28101116, -0.36622548],\n",
       "       [-0.09272022, -0.10450593, -0.5352255 ],\n",
       "       [-0.47910634,  0.41515416, -0.24438955],\n",
       "       [-0.23545095,  0.03074569, -0.57453847],\n",
       "       [-0.40371773,  0.35920107, -0.34404078],\n",
       "       [-0.3230443 ,  0.34854904, -0.4166343 ],\n",
       "       [-0.13441944, -0.03062053, -0.5008118 ],\n",
       "       [-0.15350123,  0.0344452 , -0.4137091 ],\n",
       "       [-0.61578226,  0.49293873, -0.13759665]], dtype=float32), label_ids=array([1, 1, 0, 1, 2, 1, 1, 2, 2, 1]), metrics={'test_loss': 0.9272069931030273, 'test_runtime': 0.2682, 'test_samples_per_second': 37.288, 'test_steps_per_second': 7.458})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = trainer.predict(tiny_fin_encoded['test'])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f7c1ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "977e4b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.predictions.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb4ec8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 2, 1, 1, 2, 2, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfb93fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(preds.label_ids, preds.predictions.argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5874c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(preds):\n",
    "  predictions = preds.predictions.argmax(axis=-1)\n",
    "  labels = preds.label_ids\n",
    "  accuracy = accuracy_score(preds.label_ids, preds.predictions.argmax(axis=-1))\n",
    "  return {'accuracy': accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aede36af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.794100</td>\n",
       "      <td>0.993997</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.724500</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer = Trainer(model=model, \n",
    "                  compute_metrics=get_accuracy,\n",
    "                  args=training_args, \n",
    "                  train_dataset=tiny_fin_encoded[\"train\"],\n",
    "                  eval_dataset=tiny_fin_encoded[\"validation\"],\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2543c0",
   "metadata": {},
   "source": [
    "### We see that the predictions versus the actual labels for each sentence are mostly accurate, and we also received a high accuracy score, so we are ready to proceed with the full training run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7450b653",
   "metadata": {},
   "source": [
    "## Training Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14ff1905",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 14\n",
    "logging_steps = len(fin_news_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{checkpoint}-finetuned-fin-news\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=4,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  log_level=\"error\",\n",
    "                                  optim='adamw_torch'\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22e4310c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='184' max='184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [184/184 14:37, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.670200</td>\n",
       "      <td>0.611961</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.395700</td>\n",
       "      <td>0.396746</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.228300</td>\n",
       "      <td>0.317924</td>\n",
       "      <td>0.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.307630</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer = Trainer(model=model, \n",
    "                  args=training_args, \n",
    "                  compute_metrics=get_accuracy,\n",
    "                  train_dataset=fin_news_encoded[\"train\"],\n",
    "                  eval_dataset=fin_news_encoded[\"validation\"],\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "928b3cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3076297640800476,\n",
       " 'eval_accuracy': 0.925,\n",
       " 'eval_runtime': 5.2913,\n",
       " 'eval_samples_per_second': 15.119,\n",
       " 'eval_steps_per_second': 1.134,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56b7f052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-base-cased-finetuned-fin-news'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7772b845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.7051867246627808}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis', model=model_name)\n",
    "classifier('Jan. 6 -- Ford is struggling in the face of slowing truck and SUV sales and a surfeit of up-to-date , gotta-have cars .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a528174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9416850805282593}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "302fc555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_2', 'score': 0.9790472388267517}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('For the last quarter of 2010 , Componentas net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba38502",
   "metadata": {},
   "source": [
    "The scores above mean that the model is score*100 percent sure that the last sentence has a positive sentiment.\n",
    "\n",
    "### Now we see that the model can successfully identify each of these sentences as negative, neutral, and positive. We have successfully trained a BERT model on the financial news dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b52f005",
   "metadata": {},
   "source": [
    "### Up next, I will perform a fine-tuning on the FinBert model, a pre-trained NLP model that's more specifically for analyzing the sentiment of financial text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6aea511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.0.1', '4.30.2')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from transformers import BertTokenizer, Trainer, BertForSequenceClassification, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import transformers\n",
    "torch.__version__, transformers.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78398541",
   "metadata": {},
   "source": [
    "#### Reload the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5404d58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset financial_phrasebank (/Users/thomasli/.cache/huggingface/datasets/financial_phrasebank/sentences_75agree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda7ed0273eb4e28b28258299411983d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the third quarter of 2010 , net sales increased by 5.2 % to EUR 205.5 mn , and operating profit by 34.9 % to EUR 23.5 mn .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Operating profit rose to EUR 13.1 mn from EUR 8.7 mn in the corresponding period in 2007 representing 7.7 % of net sales .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3448</th>\n",
       "      <td>Operating result for the 12-month period decreased from the profit of EUR0 .4 m while turnover decreased from EUR5 .6 m , as compared to 2004 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>HELSINKI Thomson Financial - Shares in Cargotec fell sharply in early afternoon trade after the cargo handling group posted a surprise drop in April-June profits , which overshadowed the large number of new orders received during the three months .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3450</th>\n",
       "      <td>LONDON MarketWatch -- Share prices ended lower in London Monday as a rebound in bank stocks failed to offset broader weakness for the FTSE 100 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3451</th>\n",
       "      <td>Operating profit fell to EUR 35.4 mn from EUR 68.8 mn in 2007 , including vessel sales gain of EUR 12.3 mn .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>Sales in Finland decreased by 10.5 % in January , while sales outside Finland dropped by 17 % .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                      sentence  \\\n",
       "0                                                                                                                              According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .   \n",
       "1                                               With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .   \n",
       "2                                                            For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .   \n",
       "3                                                                                                                                In the third quarter of 2010 , net sales increased by 5.2 % to EUR 205.5 mn , and operating profit by 34.9 % to EUR 23.5 mn .   \n",
       "4                                                                                                                                   Operating profit rose to EUR 13.1 mn from EUR 8.7 mn in the corresponding period in 2007 representing 7.7 % of net sales .   \n",
       "...                                                                                                                                                                                                                                                        ...   \n",
       "3448                                                                                                           Operating result for the 12-month period decreased from the profit of EUR0 .4 m while turnover decreased from EUR5 .6 m , as compared to 2004 .   \n",
       "3449  HELSINKI Thomson Financial - Shares in Cargotec fell sharply in early afternoon trade after the cargo handling group posted a surprise drop in April-June profits , which overshadowed the large number of new orders received during the three months .   \n",
       "3450                                                                                                          LONDON MarketWatch -- Share prices ended lower in London Monday as a rebound in bank stocks failed to offset broader weakness for the FTSE 100 .   \n",
       "3451                                                                                                                                              Operating profit fell to EUR 35.4 mn from EUR 68.8 mn in 2007 , including vessel sales gain of EUR 12.3 mn .   \n",
       "3452                                                                                                                                                           Sales in Finland decreased by 10.5 % in January , while sales outside Finland dropped by 17 % .   \n",
       "\n",
       "      label  \n",
       "0         1  \n",
       "1         2  \n",
       "2         2  \n",
       "3         2  \n",
       "4         2  \n",
       "...     ...  \n",
       "3448      0  \n",
       "3449      0  \n",
       "3450      0  \n",
       "3451      0  \n",
       "3452      0  \n",
       "\n",
       "[3453 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_news = load_dataset('financial_phrasebank', 'sentences_75agree')\n",
    "fin_news.set_format('pandas')\n",
    "df = fin_news['train'][:]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44f2ec3",
   "metadata": {},
   "source": [
    "#### Prepare Training/Testing/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "161c83c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2796, 2) (346, 2) (311, 2)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test, = train_test_split(df, stratify=df['label'], test_size=0.1, random_state=42)\n",
    "df_train, df_val = train_test_split(df_train, stratify=df_train['label'],test_size=0.1, random_state=42)\n",
    "print(df_train.shape, df_test.shape, df_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855372e",
   "metadata": {},
   "source": [
    "### Load FinBERT pretrained model\n",
    "\n",
    "The pretrained FinBERT model path on Huggingface is https://huggingface.co/yiyanghkust/finbert-pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3786a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-pretrain',num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-pretrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d475cd8f",
   "metadata": {},
   "source": [
    "### Prepare dataset for fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d29e5ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/346 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_train = Dataset.from_pandas(df_train)\n",
    "dataset_val = Dataset.from_pandas(df_val)\n",
    "dataset_test = Dataset.from_pandas(df_test)\n",
    "\n",
    "dataset_train = dataset_train.map(lambda e: tokenizer(e['sentence'], truncation=True, padding='max_length', max_length=128), batched=True)\n",
    "dataset_val = dataset_val.map(lambda e: tokenizer(e['sentence'], truncation=True, padding='max_length', max_length=128), batched=True)\n",
    "dataset_test = dataset_test.map(lambda e: tokenizer(e['sentence'], truncation=True, padding='max_length' , max_length=128), batched=True)\n",
    "\n",
    "dataset_train.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'])\n",
    "dataset_val.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'])\n",
    "dataset_test.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0291e9c7",
   "metadata": {},
   "source": [
    "### Define Training Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62743600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasli/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2133120745420456, 'eval_accuracy': 0.9389067524115756, 'eval_runtime': 49.0747, 'eval_samples_per_second': 6.337, 'eval_steps_per_second': 0.204, 'epoch': 1.0}\n",
      "{'eval_loss': 0.13591976463794708, 'eval_accuracy': 0.954983922829582, 'eval_runtime': 30.1679, 'eval_samples_per_second': 10.309, 'eval_steps_per_second': 0.331, 'epoch': 2.0}\n",
      "{'eval_loss': 0.11966689676046371, 'eval_accuracy': 0.9581993569131833, 'eval_runtime': 64.92, 'eval_samples_per_second': 4.791, 'eval_steps_per_second': 0.154, 'epoch': 3.0}\n",
      "{'train_runtime': 3528.7009, 'train_samples_per_second': 2.377, 'train_steps_per_second': 0.075, 'train_loss': 0.26787281036376953, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=264, training_loss=0.26787281036376953, metrics={'train_runtime': 3528.7009, 'train_samples_per_second': 2.377, 'train_steps_per_second': 0.075, 'train_loss': 0.26787281036376953, 'epoch': 3.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'accuracy' : accuracy_score(predictions, labels)}\n",
    "\n",
    "args = TrainingArguments(\n",
    "        output_dir = 'temp/',\n",
    "        evaluation_strategy = 'epoch',\n",
    "        save_strategy = 'epoch',\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='accuracy',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model,                        \n",
    "        args=args,                  \n",
    "        train_dataset=dataset_train,         \n",
    "        eval_dataset=dataset_val,           \n",
    "        compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6968721",
   "metadata": {},
   "source": [
    "### Evaluate on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5fd2c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.1803191900253296,\n",
       " 'test_accuracy': 0.9393063583815029,\n",
       " 'test_runtime': 34.43,\n",
       " 'test_samples_per_second': 10.049,\n",
       " 'test_steps_per_second': 0.319}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "trainer.predict(dataset_test).metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cbe9c4",
   "metadata": {},
   "source": [
    "### Save the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7bf26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('finbert-sentiment-fine-tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf43017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
